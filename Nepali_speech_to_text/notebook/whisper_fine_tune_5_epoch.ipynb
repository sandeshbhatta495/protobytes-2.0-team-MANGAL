{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7cedebad581d4da8a0550a00d12e22ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed083a6195374b6eb9984d9ba272a2e5","IPY_MODEL_a22973f4928b455e8ad60f4e85acc230","IPY_MODEL_b5dea084071945f79596edfff743ec45"],"layout":"IPY_MODEL_a82086c910a749f69e377b763c3b7424"}},"ed083a6195374b6eb9984d9ba272a2e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a05bdb65584670bd74af3b8fce17d6","placeholder":"‚Äã","style":"IPY_MODEL_0de621b1197141dd9daa30fabb88c021","value":"Map:‚Äá100%"}},"a22973f4928b455e8ad60f4e85acc230":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fd7cbacc6d24a90bff154b6c758ef19","max":381,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04d19e1d14a24e3a8da979d63003da2a","value":381}},"b5dea084071945f79596edfff743ec45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4744c0907db4296b0824c2502abe93a","placeholder":"‚Äã","style":"IPY_MODEL_44bd8cc50bc44220ab8dc94c6efe25ff","value":"‚Äá381/381‚Äá[00:53&lt;00:00,‚Äá‚Äá2.99s/‚Äáexamples]"}},"a82086c910a749f69e377b763c3b7424":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04a05bdb65584670bd74af3b8fce17d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0de621b1197141dd9daa30fabb88c021":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fd7cbacc6d24a90bff154b6c758ef19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d19e1d14a24e3a8da979d63003da2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4744c0907db4296b0824c2502abe93a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44bd8cc50bc44220ab8dc94c6efe25ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d830b8d81ca468bb99309f6027a5892":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20cfa50be60f4c8eb0fcdd89e0b9fb5a","IPY_MODEL_cb21a176645d46a8a38418df16eebea5","IPY_MODEL_e921cdaf19654e43ac0c0cffe6e52dda"],"layout":"IPY_MODEL_ce3e4996a7174920bd3df8a8bd4a1a27"}},"20cfa50be60f4c8eb0fcdd89e0b9fb5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_906472cc5684426ca4cdb3acc9002d5d","placeholder":"‚Äã","style":"IPY_MODEL_a1fdbdb3fc0348bd9a2c73437c467c5d","value":"Map:‚Äá100%"}},"cb21a176645d46a8a38418df16eebea5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_346e4f1452e64905a3d980a94db1f4f0","max":205,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf08fabde6fb4f07819040e417f6a3ed","value":205}},"e921cdaf19654e43ac0c0cffe6e52dda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f710ff78faef40d7970e6c36376bf86a","placeholder":"‚Äã","style":"IPY_MODEL_b52f94ca818e496ca12fd91139dc067a","value":"‚Äá205/205‚Äá[00:29&lt;00:00,‚Äá‚Äá1.65s/‚Äáexamples]"}},"ce3e4996a7174920bd3df8a8bd4a1a27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"906472cc5684426ca4cdb3acc9002d5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1fdbdb3fc0348bd9a2c73437c467c5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"346e4f1452e64905a3d980a94db1f4f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf08fabde6fb4f07819040e417f6a3ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f710ff78faef40d7970e6c36376bf86a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b52f94ca818e496ca12fd91139dc067a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Necessary Libraries\n","metadata":{"id":"iKJiVWB-oJxa"}},{"cell_type":"code","source":"!pip install --upgrade datasets[audio] transformers accelerate evaluate jiwer tensorboard gradio --quiet\n!pip install jinja2 --quiet","metadata":{"id":"YlUM7nrqnPga","outputId":"dcde84a7-21f6-4ff6-8147-c46d17d47dfc","execution":{"iopub.status.busy":"2024-09-29T13:54:18.775026Z","iopub.execute_input":"2024-09-29T13:54:18.775448Z","iopub.status.idle":"2024-09-29T13:54:44.624761Z","shell.execute_reply.started":"2024-09-29T13:54:18.775372Z","shell.execute_reply":"2024-09-29T13:54:44.623549Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict\nfrom transformers import (\n    WhisperTokenizer,\n    WhisperProcessor,\n    WhisperFeatureExtractor,\n    WhisperForConditionalGeneration,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n)","metadata":{"id":"hTogPtadoMaC","execution":{"iopub.status.busy":"2024-09-29T13:54:44.626205Z","iopub.execute_input":"2024-09-29T13:54:44.626535Z","iopub.status.idle":"2024-09-29T13:54:55.527077Z","shell.execute_reply.started":"2024-09-29T13:54:44.626500Z","shell.execute_reply":"2024-09-29T13:54:55.525969Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from datasets import Audio\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\nimport torch\nimport evaluate\n","metadata":{"id":"hIluEJIhpEbz","execution":{"iopub.status.busy":"2024-09-29T13:54:55.528242Z","iopub.execute_input":"2024-09-29T13:54:55.528878Z","iopub.status.idle":"2024-09-29T13:54:55.602526Z","shell.execute_reply.started":"2024-09-29T13:54:55.528840Z","shell.execute_reply":"2024-09-29T13:54:55.601830Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Defining Parameters","metadata":{"id":"qQSXhKq9q4Tu"}},{"cell_type":"code","source":"model_id = 'openai/whisper-small'\nout_dir = 'whisper_tiny_np'\nepochs = 5\nbatch_size = 4","metadata":{"id":"mqCI0E6apSPI","execution":{"iopub.status.busy":"2024-09-29T13:54:55.605134Z","iopub.execute_input":"2024-09-29T13:54:55.605426Z","iopub.status.idle":"2024-09-29T13:54:55.609777Z","shell.execute_reply.started":"2024-09-29T13:54:55.605394Z","shell.execute_reply":"2024-09-29T13:54:55.608899Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the Dataset","metadata":{"id":"MAiHfW9bsLp9"}},{"cell_type":"code","source":"feature_extractor = WhisperFeatureExtractor.from_pretrained(model_id)\ntokenizer = WhisperTokenizer.from_pretrained(model_id, language='Nepali', task='transcribe')\nprocessor = WhisperProcessor.from_pretrained(model_id, language='Nepali', task='transcribe')\n","metadata":{"id":"QdW9exVpr2Kv","execution":{"iopub.status.busy":"2024-09-29T13:54:55.610835Z","iopub.execute_input":"2024-09-29T13:54:55.611122Z","iopub.status.idle":"2024-09-29T13:54:57.804385Z","shell.execute_reply.started":"2024-09-29T13:54:55.611091Z","shell.execute_reply":"2024-09-29T13:54:57.803332Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_np = load_dataset(\"Naruto1/ASR_dataset\", split=\"train\", trust_remote_code=True)\n# val_np = load_dataset(\"Naruto1/ASR_dataset\", split=\"test\", trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:54:57.805530Z","iopub.execute_input":"2024-09-29T13:54:57.805911Z","iopub.status.idle":"2024-09-29T13:55:01.240656Z","shell.execute_reply.started":"2024-09-29T13:54:57.805873Z","shell.execute_reply":"2024-09-29T13:55:01.239695Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00887f6a51554ff48934b603350e0398"}},"metadata":{}}]},{"cell_type":"code","source":"train_np[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:55:01.241878Z","iopub.execute_input":"2024-09-29T13:55:01.242196Z","iopub.status.idle":"2024-09-29T13:55:01.249030Z","shell.execute_reply.started":"2024-09-29T13:55:01.242160Z","shell.execute_reply":"2024-09-29T13:55:01.248127Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'text': '‡§¨‡§≤‡§ø‡§â‡§°‡§ï‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§®‡§æ‡§Ø‡§ø‡§ï‡§æ‡§∏‡§Å‡§ó ‡§Ö‡§´‡•á‡§Ø‡§∞ ‡§µ‡§ø‡§µ‡§æ‡§π‡§∏‡•Ç‡§§‡•ç‡§∞‡§Æ‡§æ ‡§®‡§¨‡§æ‡§Å‡§ß‡§ø‡§è‡§ï‡•ã ‡§™‡•ç‡§∞‡§ï‡§∞‡§£ ‡§¨‡§≤‡§ø‡§∑‡•ç‡§† ‡§∂‡§∞‡•Ä‡§∞ ‡§¨‡§æ‡§π‡•Å‡§¨‡§≤‡§ø ‡§π‡§ø‡§∞‡•ã ‡§π‡§∞‡§ø‡§£ ‡§Æ‡§æ‡§∞‡•á‡§ï‡•ã ‡§ì‡§∞‡•ã‡§™‡§ø‡§§‡§ú‡§∏‡•ç‡§§‡§æ ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§ï‡§æ‡§∞‡§£‡§≤‡•á ‡§™‡•ç‡§∞‡§æ‡§Ø‡§É ‡§ö‡§∞‡•ç‡§ö‡§æ ‡§µ‡§ø‡§µ‡§æ‡§¶‡§Æ‡§æ ‡§Ü‡§á‡§∞‡§π‡§®‡•á ‡§ï‡§≤‡§æ‡§ï‡§æ‡§∞ ‡§∏‡§≤‡§Æ‡§æ‡§® ‡§ñ‡§æ‡§® ‡§â‡§π‡§æ‡§Å‡§ï‡•ã ‡§¶‡§æ‡§®‡§µ‡•Ä‡§∞ ‡§¶‡§Ø‡§æ‡§≤‡•Å ‡§∏‡•ç‡§µ‡§≠‡§æ‡§µ‡§ï‡§æ ‡§µ‡§ø‡§∑‡§Ø‡§Æ‡§æ ‡§ï‡§Æ‡•à ‡§ö‡§∞‡•ç‡§ö‡§æ'}"},"metadata":{}}]},{"cell_type":"code","source":"train_np","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:55:01.250192Z","iopub.execute_input":"2024-09-29T13:55:01.250478Z","iopub.status.idle":"2024-09-29T13:55:01.261562Z","shell.execute_reply.started":"2024-09-29T13:55:01.250447Z","shell.execute_reply":"2024-09-29T13:55:01.260686Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 100\n})"},"metadata":{}}]},{"cell_type":"code","source":"# atc_dataset_train = atc_dataset_train.cast_column('audio', Audio(sampling_rate=16000))\n# atc_dataset_valid = atc_dataset_valid.cast_column('audio', Audio(sampling_rate=16000))\ntrain_np = load_dataset(\"fsicoli/common_voice_19_0\", \"ne-NP\", split=\"train\", trust_remote_code=True)\nval_np = load_dataset(\"fsicoli/common_voice_19_0\", \"ne-NP\", split=\"test\", trust_remote_code=True)","metadata":{"id":"08nb_bNpsP_d","execution":{"iopub.status.busy":"2024-09-29T13:55:01.262709Z","iopub.execute_input":"2024-09-29T13:55:01.263075Z","iopub.status.idle":"2024-09-29T13:55:06.139053Z","shell.execute_reply.started":"2024-09-29T13:55:01.263034Z","shell.execute_reply":"2024-09-29T13:55:06.138177Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_np[0]","metadata":{"id":"XOsgFw4as8pH","outputId":"60907d08-cbf9-4d40-e441-0b6ac1722ab3","execution":{"iopub.status.busy":"2024-09-29T13:55:06.140088Z","iopub.execute_input":"2024-09-29T13:55:06.140361Z","iopub.status.idle":"2024-09-29T13:55:08.107551Z","shell.execute_reply.started":"2024-09-29T13:55:06.140331Z","shell.execute_reply":"2024-09-29T13:55:08.106288Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'client_id': '9f8a47cee5574b287a8f93f5498d81115cf1dfbd718ead4f2265e4400f7de0f017a58a2c8c1245e0d3ceeccffa5b110322c4f784aa8a9785e3219557cb44395e',\n 'path': '/root/.cache/huggingface/datasets/downloads/extracted/2078d4f647abb87146c4e6361776aff17e038b4472a795fd02ab22d7c2574c59/ne-NP_train_0/common_voice_ne-NP_35314089.mp3',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/2078d4f647abb87146c4e6361776aff17e038b4472a795fd02ab22d7c2574c59/ne-NP_train_0/common_voice_ne-NP_35314089.mp3',\n  'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          7.00167766e-06, -4.02070254e-05, -3.65305859e-05]),\n  'sampling_rate': 48000},\n 'sentence': '‡§Æ ‡§™‡§®‡§ø ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å ‡§π‡•à ‡§§ ‡§Ö‡§π‡§ø‡§≤‡•á ‡§≤‡§æ‡§à ‡•§',\n 'up_votes': 4,\n 'down_votes': 0,\n 'age': 'thirties',\n 'gender': 'male_masculine',\n 'accent': 'nepali',\n 'locale': 'ne-NP',\n 'segment': '',\n 'variant': ''}"},"metadata":{}}]},{"cell_type":"markdown","source":"Resmapling at 16khz","metadata":{"id":"xi84opEa09hg"}},{"cell_type":"code","source":"train_np = train_np.cast_column('audio', Audio(sampling_rate=16000))\nval_np = val_np.cast_column('audio', Audio(sampling_rate=16000))","metadata":{"id":"LC58fpS702OG","execution":{"iopub.status.busy":"2024-09-29T13:55:08.108805Z","iopub.execute_input":"2024-09-29T13:55:08.109517Z","iopub.status.idle":"2024-09-29T13:55:08.123842Z","shell.execute_reply.started":"2024-09-29T13:55:08.109480Z","shell.execute_reply":"2024-09-29T13:55:08.122933Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_np","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:55:08.125059Z","iopub.execute_input":"2024-09-29T13:55:08.125402Z","iopub.status.idle":"2024-09-29T13:55:08.131812Z","shell.execute_reply.started":"2024-09-29T13:55:08.125369Z","shell.execute_reply":"2024-09-29T13:55:08.130714Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n    num_rows: 381\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_np = train_np.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\nval_np = val_np.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])","metadata":{"id":"cjUSX-qo-GtX","execution":{"iopub.status.busy":"2024-09-29T13:55:08.137159Z","iopub.execute_input":"2024-09-29T13:55:08.137578Z","iopub.status.idle":"2024-09-29T13:55:08.152080Z","shell.execute_reply.started":"2024-09-29T13:55:08.137516Z","shell.execute_reply":"2024-09-29T13:55:08.151089Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for i, data in enumerate(train_np):\n  if not 'sentence' in data.keys() or not 'audio' in data.keys():\n    print(i, 'not found')","metadata":{"id":"1hDBvt6S8xnz","execution":{"iopub.status.busy":"2024-09-29T13:55:08.153336Z","iopub.execute_input":"2024-09-29T13:55:08.153719Z","iopub.status.idle":"2024-09-29T13:55:09.715859Z","shell.execute_reply.started":"2024-09-29T13:55:08.153677Z","shell.execute_reply":"2024-09-29T13:55:09.714996Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(batch):\n  audio = batch['audio']\n  batch['input_features'] = feature_extractor(audio['array'], sampling_rate=audio['sampling_rate']).input_features[0]\n  batch['labels'] =  tokenizer(batch['sentence']).input_ids\n  return batch\n\n\ntrain_np = train_np.map(\n    prepare_dataset,\n    num_proc=1\n)\n\nval_np = val_np.map(\n    prepare_dataset,\n    num_proc=1\n)","metadata":{"id":"hGQnEF3TtW-q","outputId":"c203ab2d-72c0-4c36-cb01-547a049e7f30","execution":{"iopub.status.busy":"2024-09-29T13:55:09.717193Z","iopub.execute_input":"2024-09-29T13:55:09.717566Z","iopub.status.idle":"2024-09-29T13:55:14.994239Z","shell.execute_reply.started":"2024-09-29T13:55:09.717514Z","shell.execute_reply":"2024-09-29T13:55:14.993460Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_np[0].keys(), val_np[0].keys()","metadata":{"id":"5k1WwGOB8Ntu","outputId":"e6fd8ce8-7389-41a1-8284-20aa228a906b","execution":{"iopub.status.busy":"2024-09-29T13:55:14.995328Z","iopub.execute_input":"2024-09-29T13:55:14.995696Z","iopub.status.idle":"2024-09-29T13:55:15.300896Z","shell.execute_reply.started":"2024-09-29T13:55:14.995661Z","shell.execute_reply":"2024-09-29T13:55:15.299762Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(dict_keys(['audio', 'sentence', 'variant', 'input_features', 'labels']),\n dict_keys(['audio', 'sentence', 'variant', 'input_features', 'labels']))"},"metadata":{}}]},{"cell_type":"code","source":"input_str = train_np[0][\"sentence\"]\nlabels = tokenizer(input_str).input_ids\ndecoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\ndecoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n\nprint(f\"Input:                 {input_str}\")\nprint(f\"Decoded w/ special:    {decoded_with_special}\")\nprint(f\"Decoded w/out special: {decoded_str}\")\nprint(f\"Are equal:             {input_str == decoded_str}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:55:15.302238Z","iopub.execute_input":"2024-09-29T13:55:15.302596Z","iopub.status.idle":"2024-09-29T13:55:15.527128Z","shell.execute_reply.started":"2024-09-29T13:55:15.302561Z","shell.execute_reply":"2024-09-29T13:55:15.526075Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Input:                 ‡§Æ ‡§™‡§®‡§ø ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å ‡§π‡•à ‡§§ ‡§Ö‡§π‡§ø‡§≤‡•á ‡§≤‡§æ‡§à ‡•§\nDecoded w/ special:    <|startoftranscript|><|ne|><|transcribe|><|notimestamps|>‡§Æ ‡§™‡§®‡§ø ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å ‡§π‡•à ‡§§ ‡§Ö‡§π‡§ø‡§≤‡•á ‡§≤‡§æ‡§à ‡•§<|endoftext|>\nDecoded w/out special: ‡§Æ ‡§™‡§®‡§ø ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å ‡§π‡•à ‡§§ ‡§Ö‡§π‡§ø‡§≤‡•á ‡§≤‡§æ‡§à ‡•§\nAre equal:             True\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Preparing the Model\n","metadata":{}},{"cell_type":"code","source":"from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n\nprocessor = AutoProcessor.from_pretrained(\"/kaggle/input/whisper_nepali/transformers/default/1/my_model_directory\")\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\"/kaggle/input/whisper_nepali/transformers/default/1/my_model_directory\")\n\nmodel.generation_config.task = 'transcribe'\nmodel.generation_config.language = 'nepali'\nmodel.generation_config.forced_decoder_ids = None","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:56:28.950431Z","iopub.execute_input":"2024-09-29T13:56:28.951082Z","iopub.status.idle":"2024-09-29T13:56:31.499408Z","shell.execute_reply.started":"2024-09-29T13:56:28.951039Z","shell.execute_reply":"2024-09-29T13:56:31.498501Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    decoder_start_token_id: int\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need different padding methods\n        # first treat the audio inputs by simply returning torch tensors\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        # get the tokenized label sequences\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        # pad the labels to max length\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        # if bos token is appended in previous tokenization step,\n        # cut bos token here as it's append later anyways\n        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n\n        return batch\n","metadata":{"id":"8EQbJrq9u-U9","execution":{"iopub.status.busy":"2024-09-29T13:56:32.768051Z","iopub.execute_input":"2024-09-29T13:56:32.768986Z","iopub.status.idle":"2024-09-29T13:56:32.778811Z","shell.execute_reply.started":"2024-09-29T13:56:32.768941Z","shell.execute_reply":"2024-09-29T13:56:32.777862Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n    processor=processor,\n    decoder_start_token_id=model.config.decoder_start_token_id,\n)","metadata":{"id":"OX_ronBaykBB","execution":{"iopub.status.busy":"2024-09-29T13:56:32.923670Z","iopub.execute_input":"2024-09-29T13:56:32.924001Z","iopub.status.idle":"2024-09-29T13:56:32.928130Z","shell.execute_reply.started":"2024-09-29T13:56:32.923966Z","shell.execute_reply":"2024-09-29T13:56:32.927225Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Defining evaluation metrices","metadata":{"id":"EHEutjMXyuMg"}},{"cell_type":"code","source":"metric = evaluate.load('wer')\n\ndef compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    # replace -100 with the pad_token_id\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\n\n    # we do not want to group tokens when computing the metrics\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n\n    return {'wer': wer}","metadata":{"id":"W3usZ5Vbyrhp","execution":{"iopub.status.busy":"2024-09-29T13:56:33.237128Z","iopub.execute_input":"2024-09-29T13:56:33.237442Z","iopub.status.idle":"2024-09-29T13:56:34.170667Z","shell.execute_reply.started":"2024-09-29T13:56:33.237409Z","shell.execute_reply":"2024-09-29T13:56:34.169873Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=out_dir,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    gradient_accumulation_steps=1,\n    learning_rate=0.00001,\n    warmup_steps=500,\n    bf16=False,\n    fp16=True,\n    num_train_epochs=epochs,\n    evaluation_strategy='epoch',\n    logging_strategy='epoch',\n    save_strategy='epoch',\n    predict_with_generate=True,\n    generation_max_length=225,\n    report_to=['tensorboard'],\n    load_best_model_at_end=True,\n    metric_for_best_model='wer',\n    greater_is_better=False,\n    dataloader_num_workers=2,\n    save_total_limit=2,\n    lr_scheduler_type='constant',\n    seed=42,\n    data_seed=42\n)","metadata":{"id":"K8M8nN7Dy0ff","outputId":"21de1235-42a7-40ed-ce1d-f28af50d9da8","execution":{"iopub.status.busy":"2024-09-29T13:56:34.172493Z","iopub.execute_input":"2024-09-29T13:56:34.173284Z","iopub.status.idle":"2024-09-29T13:56:34.295666Z","shell.execute_reply.started":"2024-09-29T13:56:34.173237Z","shell.execute_reply":"2024-09-29T13:56:34.294698Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=train_np,\n    eval_dataset=val_np,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor.feature_extractor,\n)","metadata":{"id":"xVVbdHAXy31S","outputId":"fb8370b7-7138-47e0-8daf-790ff59fd9c0","execution":{"iopub.status.busy":"2024-09-29T13:56:34.296846Z","iopub.execute_input":"2024-09-29T13:56:34.297143Z","iopub.status.idle":"2024-09-29T13:56:34.857241Z","shell.execute_reply.started":"2024-09-29T13:56:34.297109Z","shell.execute_reply":"2024-09-29T13:56:34.856434Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset(\"spktsagar/openslr-nepali-asr-cleaned\", name=\"cleaned\", split='train')","metadata":{"id":"gogJaZmwMsTv","execution":{"iopub.status.busy":"2024-09-29T14:15:32.973964Z","iopub.execute_input":"2024-09-29T14:15:32.974748Z","iopub.status.idle":"2024-09-29T14:27:23.057181Z","shell.execute_reply.started":"2024-09-29T14:15:32.974700Z","shell.execute_reply":"2024-09-29T14:27:23.056213Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"openslr-nepali-asr-cleaned.py:   0%|          | 0.00/6.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42927aaac2874524a7f1fb4120066b4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.73k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9090a0370886430183a7bfc68b3375b8"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for spktsagar/openslr-nepali-asr-cleaned contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/spktsagar/openslr-nepali-asr-cleaned.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"utt_spk_text_clean.tsv:   0%|          | 0.00/12.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"932a8db8e5264b1483c9e2aab1c7f152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_0.zip:   0%|          | 0.00/379M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1011cd8c54e5408aafb0e4fbbfd53391"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_1.zip:   0%|          | 0.00/372M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0ca8c86001740d9aaa27bb07648f1d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_2.zip:   0%|          | 0.00/376M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d951f5fe245e4823aeae717bca117027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_3.zip:   0%|          | 0.00/367M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a41827424da471dbdd44dbfaac2d17d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_4.zip:   0%|          | 0.00/372M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab990cf0bfca490fb0d5a1e0f8677a08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_5.zip:   0%|          | 0.00/366M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"066a836ea2894113808c9413af71b72f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_6.zip:   0%|          | 0.00/376M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eabd49f7f07f4de28e289f6eb6b78f4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_7.zip:   0%|          | 0.00/377M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c0aae98c36842ff87d0c61a57d27015"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_8.zip:   0%|          | 0.00/375M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a496867eb5d4b319d50f901639a3ed9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_9.zip:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ad818bf14a3458bb27a8cd790e6a63e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_a.zip:   0%|          | 0.00/376M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9362d36dc3e040bea171251f74a46bf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_b.zip:   0%|          | 0.00/373M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a50a2a25b394196a64d0038d21d4f05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_c.zip:   0%|          | 0.00/370M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f73457387c3417c970ae40b0c8862f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_d.zip:   0%|          | 0.00/377M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a22418fdd8d4b8e83d0b41047c34d2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_e.zip:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1026b7d315b14e2a981941b7dee87855"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asr_nepali_f.zip:   0%|          | 0.00/368M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19b931d096f9459da2923827202b08ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/157905 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a8b3b5bbb8f422da0f01a58dee82916"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"GEak1sdXy68O","outputId":"c87fec96-aa39-41f1-9234-e44a7b189e5b","execution":{"iopub.status.busy":"2024-09-29T13:56:53.570194Z","iopub.execute_input":"2024-09-29T13:56:53.571090Z","iopub.status.idle":"2024-09-29T14:15:32.971610Z","shell.execute_reply.started":"2024-09-29T13:56:53.571048Z","shell.execute_reply":"2024-09-29T14:15:32.970537Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [240/240 18:33, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.054700</td>\n      <td>0.515619</td>\n      <td>56.312165</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.030700</td>\n      <td>0.515328</td>\n      <td>54.781943</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.024200</td>\n      <td>0.546078</td>\n      <td>54.705432</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.019400</td>\n      <td>0.553506</td>\n      <td>55.011477</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.019300</td>\n      <td>0.563238</td>\n      <td>54.781943</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nThere were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=240, training_loss=0.029658036927382152, metrics={'train_runtime': 1118.5552, 'train_samples_per_second': 1.703, 'train_steps_per_second': 0.215, 'total_flos': 5.612986036224e+17, 'train_loss': 0.029658036927382152, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"GM-TM6JcNMF_","outputId":"a1fee087-ed2b-4d29-d00b-6c0a17ea1897","execution":{"iopub.status.busy":"2024-09-29T14:27:23.058409Z","iopub.execute_input":"2024-09-29T14:27:23.058741Z","iopub.status.idle":"2024-09-29T14:27:23.074344Z","shell.execute_reply.started":"2024-09-29T14:27:23.058706Z","shell.execute_reply":"2024-09-29T14:27:23.073529Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{'utterance_id': '4aa1fdca33',\n 'speaker_id': '6a6d1',\n 'utterance': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/b3f557561e70f0ebaa552943ee134754d6a731f729ff40b6e18072b1707b15c7/cleaned/asr_nepali/data/4a/4aa1fdca33.flac',\n  'array': array([-3.23486328e-03, -2.38037109e-03,  6.43920898e-03, ...,\n          9.15527344e-05,  9.15527344e-05, -5.49316406e-04]),\n  'sampling_rate': 16000},\n 'transcription': '‡•¶‡•¶‡•≠ ‡§Æ‡§ø‡§≤‡§ï‡•ã ‡§¶‡•Ç‡§∞‡•Ä‡§Æ‡§æ',\n 'num_frames': 43200}"},"metadata":{}}]},{"cell_type":"markdown","source":"### For inference","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ndataloader = DataLoader(val_np, batch_size=4, collate_fn=data_collator)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:27:23.077021Z","iopub.execute_input":"2024-09-29T14:27:23.077476Z","iopub.status.idle":"2024-09-29T14:27:23.082129Z","shell.execute_reply.started":"2024-09-29T14:27:23.077423Z","shell.execute_reply":"2024-09-29T14:27:23.081256Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"batch[\"input_features\"].shape","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:33:21.005243Z","iopub.execute_input":"2024-09-29T14:33:21.006062Z","iopub.status.idle":"2024-09-29T14:33:21.012265Z","shell.execute_reply.started":"2024-09-29T14:33:21.006018Z","shell.execute_reply":"2024-09-29T14:33:21.011404Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 80, 3000])"},"metadata":{}}]},{"cell_type":"code","source":"# Iterate through batches and get model predictions\nfor batch in dataloader:\n    input_features = batch[\"input_features\"].to('cuda')\n    labels = batch[\"labels\"]\n\n    # Perform inference (using no_grad for evaluation)\n    with torch.no_grad():\n        generated_ids = model.generate(input_features, language='ne')\n\n    # Decode the predicted token IDs into text\n    predictions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n    sents = processor.batch_decode(labels, skip_special_tokens=True)\n    # Print or store predictions\n    for pred, sen in zip(predictions, sents):\n        print(f'GT:{sen}.......... Pred: {pred}')\n        \n    break","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:29:08.631627Z","iopub.execute_input":"2024-09-29T14:29:08.632086Z","iopub.status.idle":"2024-09-29T14:29:10.675485Z","shell.execute_reply.started":"2024-09-29T14:29:08.632045Z","shell.execute_reply":"2024-09-29T14:29:10.674422Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"GT:‡§™‡§æ‡§®‡•Ä ‡§§‡§ø‡§∞‡•ç‡§ñ‡§æ ‡§≤‡§æ‡§ó‡•ç‡§Ø‡•ã ‡•§.......... Pred: ‡§™‡§æ‡§®‡•Ä ‡§§‡§ø‡§∞‡•ç‡§ï‡§æ ‡§≤‡§æ‡§ó‡•ç‡§Ø‡•ã ‡•§\nGT:‡§Æ‡§æ‡§ó ‡§∞ ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ ‡§°‡§ø‡§ú‡•á‡§≤‡§ï‡•à ‡§¨‡§¢‡•ç‡§Ø‡•ã ‡•§.......... Pred: ‡§Æ‡§æ‡§ó‡•ç‡§∞ ‡§Æ‡§π‡§§‡•ç‡§µ ‡§°‡§ø‡§ú‡§∞‡§ï‡•à ‡§™‡§¢‡•ç‡§Ø‡§æ‡•§\nGT:‡§ï‡§æ‡§Æ ‡§∞ ‡§™‡§¢‡§æ‡§á‡§≤‡•á ‡§ó‡§∞‡•ç‡§¶‡§æ ‡§®‡•à ‡§π‡•ã ‡§ß‡•á‡§∞‡•à ‡§§ ‡•§.......... Pred: ‡§ï‡§æ‡§Æ‡•ç‡§∞ ‡§™‡§¢‡§æ‡§á‡§≤‡•á ‡§ï‡§∞‡•ç‡§¶‡§æ ‡§®‡•à ‡§π‡•Å‡§•‡§ø‡§∞‡•Ä ‡§§ ‡•§\nGT:‡§π‡§ø‡§ú‡•ã ‡§ó‡§∞‡•á‡§ï‡•ã ‡§Ü‡§Æ‡§æ‡§≤‡§æ‡§à ‡§´‡•ã‡§® ‡•§.......... Pred: ‡§è‡§ú ‡§ó‡§∞‡•á‡§ï‡•ã ‡§π‡§æ‡§Æ‡§æ‡§≤‡§æ‡§à ‡§´‡•Å‡§® ‡•§\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the directory where you want to save the model\nsave_directory = \"./my_model_directory\"\n\n# Save the model\nmodel.save_pretrained(save_directory)\n\n# Save the processor/tokenizer (if applicable)\nprocessor.save_pretrained(save_directory)  # or tokenizer.save_pretrained(save_directory)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:35:51.443755Z","iopub.execute_input":"2024-09-29T14:35:51.444707Z","iopub.status.idle":"2024-09-29T14:35:54.192320Z","shell.execute_reply.started":"2024-09-29T14:35:51.444655Z","shell.execute_reply":"2024-09-29T14:35:54.191361Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"!zip -r /kaggle/working/my_model_directory.zip /kaggle/working/my_model_directory","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:36:53.110392Z","iopub.execute_input":"2024-09-29T14:36:53.110816Z","iopub.status.idle":"2024-09-29T14:37:46.529599Z","shell.execute_reply.started":"2024-09-29T14:36:53.110773Z","shell.execute_reply":"2024-09-29T14:37:46.528555Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/working/my_model_directory/ (stored 0%)\n  adding: kaggle/working/my_model_directory/preprocessor_config.json (deflated 42%)\n  adding: kaggle/working/my_model_directory/vocab.json (deflated 69%)\n  adding: kaggle/working/my_model_directory/generation_config.json (deflated 72%)\n  adding: kaggle/working/my_model_directory/normalizer.json (deflated 81%)\n  adding: kaggle/working/my_model_directory/model.safetensors (deflated 8%)\n  adding: kaggle/working/my_model_directory/merges.txt (deflated 54%)\n  adding: kaggle/working/my_model_directory/special_tokens_map.json (deflated 80%)\n  adding: kaggle/working/my_model_directory/tokenizer_config.json (deflated 96%)\n  adding: kaggle/working/my_model_directory/config.json (deflated 59%)\n  adding: kaggle/working/my_model_directory/added_tokens.json (deflated 80%)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}